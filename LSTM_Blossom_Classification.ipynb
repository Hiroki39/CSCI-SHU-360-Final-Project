{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = 30\n",
    "        self.lstm = nn.LSTM(input_size=20, hidden_size=self.hidden_layer_size, num_layers=2, dropout=0.5)   \n",
    "        self.linear = nn.Linear(self.hidden_layer_size, 11)  # equivalent to Dense in keras\n",
    "        self.hidden_cell = (torch.zeros(2, 1, self.hidden_layer_size),\n",
    "                            torch.zeros(2, 1, self.hidden_layer_size))\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        classifications = self.softmax(predictions)\n",
    "        return classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt(\"ML_Datasets/processed_data_classification20.csv\", delimiter=\",\")\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# normalize the data\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "# oversample the data to reduce imbalance\n",
    "X, y = SMOTE().fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation, test split\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train).type(torch.LongTensor)\n",
    "X_val = torch.Tensor(X_val)\n",
    "y_val = torch.Tensor(y_val).type(torch.LongTensor)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {\n",
    "    \"train\": [],\n",
    "    \"val\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    \"train\": [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-2-81d135f2e8dc>:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  classifications = self.softmax(predictions)\n",
      "Epoch 0: | Train Loss: 2.39762 | Val Loss: 2.39787 | Train Acc: 9.122 | Val Acc: 8.954\n",
      "Epoch 1: | Train Loss: 2.39781 | Val Loss: 2.39793 | Train Acc: 9.188 | Val Acc: 8.954\n",
      "Epoch 2: | Train Loss: 2.39835 | Val Loss: 2.39780 | Train Acc: 9.188 | Val Acc: 8.954\n",
      "Epoch 3: | Train Loss: 2.39807 | Val Loss: 2.39789 | Train Acc: 9.188 | Val Acc: 8.954\n",
      "Epoch 4: | Train Loss: 2.39766 | Val Loss: 2.39787 | Train Acc: 9.187 | Val Acc: 8.954\n",
      "Epoch 5: | Train Loss: 2.39792 | Val Loss: 2.39787 | Train Acc: 9.180 | Val Acc: 8.847\n",
      "Epoch 6: | Train Loss: 2.39778 | Val Loss: 2.39776 | Train Acc: 9.109 | Val Acc: 8.870\n",
      "Epoch 7: | Train Loss: 2.39762 | Val Loss: 2.39763 | Train Acc: 9.816 | Val Acc: 13.123\n",
      "Epoch 8: | Train Loss: 2.39754 | Val Loss: 2.39759 | Train Acc: 11.034 | Val Acc: 9.648\n",
      "Epoch 9: | Train Loss: 2.39728 | Val Loss: 2.39730 | Train Acc: 10.987 | Val Acc: 9.139\n",
      "Epoch 10: | Train Loss: 2.39703 | Val Loss: 2.39696 | Train Acc: 10.289 | Val Acc: 9.132\n",
      "Epoch 11: | Train Loss: 2.39691 | Val Loss: 2.39669 | Train Acc: 10.007 | Val Acc: 9.132\n",
      "Epoch 12: | Train Loss: 2.39673 | Val Loss: 2.39634 | Train Acc: 9.980 | Val Acc: 9.132\n",
      "Epoch 13: | Train Loss: 2.39647 | Val Loss: 2.39576 | Train Acc: 9.868 | Val Acc: 9.132\n",
      "Epoch 14: | Train Loss: 2.39593 | Val Loss: 2.39479 | Train Acc: 9.731 | Val Acc: 9.132\n",
      "Epoch 15: | Train Loss: 2.39494 | Val Loss: 2.39380 | Train Acc: 9.821 | Val Acc: 9.136\n",
      "Epoch 16: | Train Loss: 2.39404 | Val Loss: 2.39225 | Train Acc: 9.949 | Val Acc: 9.155\n",
      "Epoch 17: | Train Loss: 2.39295 | Val Loss: 2.39027 | Train Acc: 10.148 | Val Acc: 9.210\n",
      "Epoch 18: | Train Loss: 2.39136 | Val Loss: 2.38803 | Train Acc: 10.499 | Val Acc: 9.253\n",
      "Epoch 19: | Train Loss: 2.38963 | Val Loss: 2.38522 | Train Acc: 10.608 | Val Acc: 9.373\n",
      "Epoch 20: | Train Loss: 2.38740 | Val Loss: 2.38244 | Train Acc: 11.163 | Val Acc: 9.340\n",
      "Epoch 21: | Train Loss: 2.38515 | Val Loss: 2.38013 | Train Acc: 10.951 | Val Acc: 13.639\n",
      "Epoch 22: | Train Loss: 2.38408 | Val Loss: 2.37654 | Train Acc: 12.898 | Val Acc: 10.038\n",
      "Epoch 23: | Train Loss: 2.38103 | Val Loss: 2.37423 | Train Acc: 11.939 | Val Acc: 9.765\n",
      "Epoch 24: | Train Loss: 2.37942 | Val Loss: 2.37045 | Train Acc: 11.740 | Val Acc: 14.271\n",
      "Epoch 25: | Train Loss: 2.37645 | Val Loss: 2.36785 | Train Acc: 13.307 | Val Acc: 14.914\n",
      "Epoch 26: | Train Loss: 2.37482 | Val Loss: 2.36516 | Train Acc: 13.661 | Val Acc: 13.382\n",
      "Epoch 27: | Train Loss: 2.37224 | Val Loss: 2.36307 | Train Acc: 13.168 | Val Acc: 13.425\n",
      "Epoch 28: | Train Loss: 2.37026 | Val Loss: 2.36019 | Train Acc: 13.223 | Val Acc: 15.238\n",
      "Epoch 29: | Train Loss: 2.36779 | Val Loss: 2.35849 | Train Acc: 14.039 | Val Acc: 15.770\n",
      "Epoch 30: | Train Loss: 2.36664 | Val Loss: 2.35607 | Train Acc: 14.329 | Val Acc: 15.537\n",
      "Epoch 31: | Train Loss: 2.36424 | Val Loss: 2.35453 | Train Acc: 14.290 | Val Acc: 15.241\n",
      "Epoch 32: | Train Loss: 2.36240 | Val Loss: 2.35276 | Train Acc: 14.239 | Val Acc: 15.679\n",
      "Epoch 33: | Train Loss: 2.36033 | Val Loss: 2.35170 | Train Acc: 14.562 | Val Acc: 15.939\n",
      "Epoch 34: | Train Loss: 2.35856 | Val Loss: 2.34955 | Train Acc: 14.955 | Val Acc: 15.897\n",
      "Epoch 35: | Train Loss: 2.35694 | Val Loss: 2.34813 | Train Acc: 14.873 | Val Acc: 15.848\n",
      "Epoch 36: | Train Loss: 2.35525 | Val Loss: 2.34715 | Train Acc: 14.965 | Val Acc: 16.001\n",
      "Epoch 37: | Train Loss: 2.35382 | Val Loss: 2.34572 | Train Acc: 15.237 | Val Acc: 16.023\n",
      "Epoch 38: | Train Loss: 2.35272 | Val Loss: 2.34503 | Train Acc: 15.225 | Val Acc: 16.026\n",
      "Epoch 39: | Train Loss: 2.35127 | Val Loss: 2.34377 | Train Acc: 15.347 | Val Acc: 15.803\n",
      "Epoch 40: | Train Loss: 2.35041 | Val Loss: 2.34365 | Train Acc: 15.263 | Val Acc: 15.842\n",
      "Epoch 41: | Train Loss: 2.34925 | Val Loss: 2.34236 | Train Acc: 15.613 | Val Acc: 16.030\n",
      "Epoch 42: | Train Loss: 2.34813 | Val Loss: 2.34235 | Train Acc: 15.387 | Val Acc: 16.205\n",
      "Epoch 43: | Train Loss: 2.34734 | Val Loss: 2.34095 | Train Acc: 15.656 | Val Acc: 16.377\n",
      "Epoch 44: | Train Loss: 2.34590 | Val Loss: 2.34033 | Train Acc: 15.611 | Val Acc: 16.328\n",
      "Epoch 45: | Train Loss: 2.34510 | Val Loss: 2.34018 | Train Acc: 15.702 | Val Acc: 16.429\n",
      "Epoch 46: | Train Loss: 2.34414 | Val Loss: 2.33880 | Train Acc: 15.946 | Val Acc: 16.438\n",
      "Epoch 47: | Train Loss: 2.34316 | Val Loss: 2.33832 | Train Acc: 15.912 | Val Acc: 16.325\n",
      "Epoch 48: | Train Loss: 2.34268 | Val Loss: 2.33821 | Train Acc: 15.908 | Val Acc: 16.516\n",
      "Epoch 49: | Train Loss: 2.34227 | Val Loss: 2.33671 | Train Acc: 16.159 | Val Acc: 16.708\n",
      "Epoch 50: | Train Loss: 2.34085 | Val Loss: 2.33652 | Train Acc: 16.206 | Val Acc: 16.769\n",
      "Epoch 51: | Train Loss: 2.34061 | Val Loss: 2.33606 | Train Acc: 16.176 | Val Acc: 17.250\n",
      "Epoch 52: | Train Loss: 2.33996 | Val Loss: 2.33470 | Train Acc: 16.801 | Val Acc: 17.626\n",
      "Epoch 53: | Train Loss: 2.33854 | Val Loss: 2.33478 | Train Acc: 17.060 | Val Acc: 17.717\n",
      "Epoch 54: | Train Loss: 2.33877 | Val Loss: 2.33343 | Train Acc: 16.950 | Val Acc: 18.067\n",
      "Epoch 55: | Train Loss: 2.33751 | Val Loss: 2.33275 | Train Acc: 17.479 | Val Acc: 18.233\n",
      "Epoch 56: | Train Loss: 2.33690 | Val Loss: 2.33233 | Train Acc: 17.721 | Val Acc: 18.612\n",
      "Epoch 57: | Train Loss: 2.33626 | Val Loss: 2.33087 | Train Acc: 17.706 | Val Acc: 18.778\n",
      "Epoch 58: | Train Loss: 2.33505 | Val Loss: 2.33040 | Train Acc: 18.125 | Val Acc: 18.865\n",
      "Epoch 59: | Train Loss: 2.33460 | Val Loss: 2.32975 | Train Acc: 18.277 | Val Acc: 19.070\n",
      "Epoch 60: | Train Loss: 2.33386 | Val Loss: 2.32862 | Train Acc: 18.200 | Val Acc: 19.209\n",
      "Epoch 61: | Train Loss: 2.33292 | Val Loss: 2.32814 | Train Acc: 18.449 | Val Acc: 19.203\n",
      "Epoch 62: | Train Loss: 2.33260 | Val Loss: 2.32765 | Train Acc: 18.433 | Val Acc: 19.190\n",
      "Epoch 63: | Train Loss: 2.33188 | Val Loss: 2.32666 | Train Acc: 18.474 | Val Acc: 19.342\n",
      "Epoch 64: | Train Loss: 2.33095 | Val Loss: 2.32605 | Train Acc: 18.622 | Val Acc: 19.345\n",
      "Epoch 65: | Train Loss: 2.33014 | Val Loss: 2.32569 | Train Acc: 18.682 | Val Acc: 19.355\n",
      "Epoch 66: | Train Loss: 2.32981 | Val Loss: 2.32492 | Train Acc: 18.706 | Val Acc: 19.375\n",
      "Epoch 67: | Train Loss: 2.32957 | Val Loss: 2.32414 | Train Acc: 18.716 | Val Acc: 19.433\n",
      "Epoch 68: | Train Loss: 2.32837 | Val Loss: 2.32347 | Train Acc: 18.894 | Val Acc: 19.472\n",
      "Epoch 69: | Train Loss: 2.32814 | Val Loss: 2.32295 | Train Acc: 18.740 | Val Acc: 19.540\n",
      "Epoch 70: | Train Loss: 2.32741 | Val Loss: 2.32263 | Train Acc: 18.980 | Val Acc: 19.459\n",
      "Epoch 71: | Train Loss: 2.32706 | Val Loss: 2.32216 | Train Acc: 18.892 | Val Acc: 19.436\n",
      "Epoch 72: | Train Loss: 2.32654 | Val Loss: 2.32193 | Train Acc: 18.865 | Val Acc: 19.339\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    model.hidden_cell = (torch.zeros(2, 1, model.hidden_layer_size),\n",
    "                         torch.zeros(2, 1, model.hidden_layer_size))\n",
    "\n",
    "    y_preds = model(X_train)\n",
    "    _, y_pred_tags = torch.max(y_preds, dim=1)\n",
    "\n",
    "    train_loss = loss_function(y_preds, y_train)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    correct_pred = (y_pred_tags == y_train).float()\n",
    "    train_acc = correct_pred.sum() * 100 / len(correct_pred)\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        y_val_preds = model(X_val)\n",
    "        _, y_val_pred_tags = torch.max(y_val_preds, dim = 1)\n",
    "\n",
    "        correct_val_pred = (y_val_pred_tags == y_val).float()\n",
    "\n",
    "        val_loss = loss_function(y_val_preds, y_val)\n",
    "        val_acc = correct_val_pred.sum() * 100 / len(correct_val_pred)\n",
    "    \n",
    "    loss_stats['train'].append(train_loss)\n",
    "    loss_stats['val'].append(val_loss)\n",
    "    accuracy_stats['train'].append(train_acc)\n",
    "    accuracy_stats['val'].append(val_acc)\n",
    "\n",
    "    print(f'Epoch {i}: | Train Loss: {train_loss:.5f} | Val Loss: {val_loss:.5f} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Loss: 2.3103382587\n",
      "Accuracy: 19.9258928001\n",
      "Precision: 19.9258928001\n",
      "Recall: 13.9103545761\n",
      "F1 Score: 14.3619214968\n",
      "<ipython-input-2-81d135f2e8dc>:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  classifications = self.softmax(predictions)\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "    \n",
    "with torch.no_grad():\n",
    "\n",
    "    y_test_preds = model(X_test)\n",
    "    _, y_test_pred_tags = torch.max(y_test_preds, dim = 1)\n",
    "    \n",
    "    correct_test_pred = (y_test_pred_tags == y_test).float()\n",
    "    test_loss = loss_function(y_test_preds, y_test)\n",
    "    test_acc = correct_test_pred.sum() * 100 / len(correct_test_pred)\n",
    "        \n",
    "print(f'Validation Loss: {test_loss.item():10.10f}')\n",
    "print(f'Accuracy: {metrics.accuracy_score(y_test_pred_tags, y_test)*100:10.10f}')\n",
    "print(f'Precision: {metrics.precision_score(y_test_pred_tags, y_test, average=\"macro\")*100:10.10f}')\n",
    "print(f'Recall: {metrics.recall_score(y_test_pred_tags, y_test, average=\"macro\")*100:10.10f}')\n",
    "print(f'F1 Score: {metrics.f1_score(y_test_pred_tags, y_test, average=\"macro\")*100:10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}